{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 57 columns):\n",
      "Administrative                   12330 non-null int64\n",
      "Administrative_Duration          12330 non-null float64\n",
      "Informational                    12330 non-null int64\n",
      "Informational_Duration           12330 non-null float64\n",
      "ProductRelated                   12330 non-null int64\n",
      "ProductRelated_Duration          12330 non-null float64\n",
      "BounceRates                      12330 non-null float64\n",
      "ExitRates                        12330 non-null float64\n",
      "PageValues                       12330 non-null float64\n",
      "TrafficType                      12330 non-null int64\n",
      "SpecialDay                       12330 non-null float64\n",
      "Month_Aug                        12330 non-null uint8\n",
      "Month_Dec                        12330 non-null uint8\n",
      "Month_Feb                        12330 non-null uint8\n",
      "Month_Jul                        12330 non-null uint8\n",
      "Month_June                       12330 non-null uint8\n",
      "Month_Mar                        12330 non-null uint8\n",
      "Month_May                        12330 non-null uint8\n",
      "Month_Nov                        12330 non-null uint8\n",
      "Month_Oct                        12330 non-null uint8\n",
      "Month_Sep                        12330 non-null uint8\n",
      "OperatingSystems_1               12330 non-null uint8\n",
      "OperatingSystems_2               12330 non-null uint8\n",
      "OperatingSystems_3               12330 non-null uint8\n",
      "OperatingSystems_4               12330 non-null uint8\n",
      "OperatingSystems_5               12330 non-null uint8\n",
      "OperatingSystems_6               12330 non-null uint8\n",
      "OperatingSystems_7               12330 non-null uint8\n",
      "OperatingSystems_8               12330 non-null uint8\n",
      "Browser_1                        12330 non-null uint8\n",
      "Browser_2                        12330 non-null uint8\n",
      "Browser_3                        12330 non-null uint8\n",
      "Browser_4                        12330 non-null uint8\n",
      "Browser_5                        12330 non-null uint8\n",
      "Browser_6                        12330 non-null uint8\n",
      "Browser_7                        12330 non-null uint8\n",
      "Browser_8                        12330 non-null uint8\n",
      "Browser_9                        12330 non-null uint8\n",
      "Browser_10                       12330 non-null uint8\n",
      "Browser_11                       12330 non-null uint8\n",
      "Browser_12                       12330 non-null uint8\n",
      "Browser_13                       12330 non-null uint8\n",
      "Region_1                         12330 non-null uint8\n",
      "Region_2                         12330 non-null uint8\n",
      "Region_3                         12330 non-null uint8\n",
      "Region_4                         12330 non-null uint8\n",
      "Region_5                         12330 non-null uint8\n",
      "Region_6                         12330 non-null uint8\n",
      "Region_7                         12330 non-null uint8\n",
      "Region_8                         12330 non-null uint8\n",
      "Region_9                         12330 non-null uint8\n",
      "VisitorType_New_Visitor          12330 non-null uint8\n",
      "VisitorType_Other                12330 non-null uint8\n",
      "VisitorType_Returning_Visitor    12330 non-null uint8\n",
      "Weekend_False                    12330 non-null uint8\n",
      "Weekend_True                     12330 non-null uint8\n",
      "Revenue                          12330 non-null bool\n",
      "dtypes: bool(1), float64(7), int64(4), uint8(45)\n",
      "memory usage: 1.6 MB\n",
      "Shape of x: (12330, 56)\n",
      "Shape of y: (12330,)\n"
     ]
    }
   ],
   "source": [
    "myData=pd.read_csv('imputedData.csv')\n",
    "myData.head()\n",
    "\n",
    "#One hot encoding of categorical variables\n",
    "\n",
    "#Create list with features to be dummified cols.\n",
    "nonum_feats_names = ['Month','OperatingSystems','Browser','Region','VisitorType','Weekend']\n",
    "\n",
    "\n",
    "dataModel = pd.concat([myData[['Administrative', 'Administrative_Duration', 'Informational','Informational_Duration', \n",
    "                              'ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues',\n",
    "                               'TrafficType','SpecialDay']],\n",
    "                       pd.get_dummies(myData[nonum_feats_names].astype('category')),myData['Revenue']],axis=1)\n",
    "                      \n",
    "dataModel.info()\n",
    "\n",
    "\n",
    "#Label Encoding of revenue\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "myData['Revenue'] = le.fit_transform(myData['Revenue'])\n",
    "myData['Revenue'].value_counts()\n",
    "\n",
    "myData['Revenue'].head()\n",
    "\n",
    "# getting dependent and independent variables\n",
    "\n",
    "x = dataModel\n",
    "# removing the target column revenue from x\n",
    "x = x.drop(['Revenue'], axis = 1)\n",
    "\n",
    "y = myData['Revenue']\n",
    "\n",
    "# checking the shapes\n",
    "print(\"Shape of x:\", x.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train : (8631, 56)\n",
      "Shape of y_train : (8631,)\n",
      "Shape of x_test : (3699, 56)\n",
      "Shape of y_test : (3699,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_Train, X_Test, y_Train, y_Test = train_test_split(x, y, test_size = 0.3, random_state = 42,shuffle=True,stratify=y)\n",
    "\n",
    "# checking the shapes\n",
    "\n",
    "print(\"Shape of x_train :\", X_Train.shape)\n",
    "print(\"Shape of y_train :\", y_Train.shape)\n",
    "print(\"Shape of x_test :\", X_Test.shape)\n",
    "print(\"Shape of y_test :\", y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.845209\n",
       "1    0.154791\n",
       "Name: Revenue, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_Train,columns=['Revenue']).Revenue.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#SCALING WITH STANDARD Z SCORE SCALER\n",
    "#Scaling the data first fitting it and transforming the training set\n",
    "#to later apply the fit to transform the test set.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols_names = ['Administrative', 'Administrative_Duration', 'Informational','Informational_Duration', \n",
    "                              'ProductRelated','ProductRelated_Duration','BounceRates','ExitRates','PageValues',\n",
    "                               'TrafficType','SpecialDay']\n",
    "#Instantiate Satandard Scaler\n",
    "scaler = StandardScaler()\n",
    "#Fit transform the numerical features in the training dataset to a new dataframe\n",
    "scaled_numfeats_train = pd.DataFrame(scaler.fit_transform(X_Train[num_cols_names]), \n",
    "                                     columns=num_cols_names, index= X_Train.index)\n",
    "#Integrate scaled values to the training set\n",
    "for col in num_cols_names:\n",
    "    X_Train[col] = scaled_numfeats_train[col]\n",
    "    \n",
    "    \n",
    "#Transform the numerical features inthe training dataset to a new dataframe\n",
    "scaled_numfeats_test = pd.DataFrame(scaler.transform(X_Test[num_cols_names]),\n",
    "                                    columns=num_cols_names, index= X_Test.index)\n",
    "#Integrate scaled values to the test set\n",
    "for col in num_cols_names:\n",
    "    X_Test[col] = scaled_numfeats_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>...</th>\n",
       "      <th>Region_5</th>\n",
       "      <th>Region_6</th>\n",
       "      <th>Region_7</th>\n",
       "      <th>Region_8</th>\n",
       "      <th>Region_9</th>\n",
       "      <th>VisitorType_New_Visitor</th>\n",
       "      <th>VisitorType_Other</th>\n",
       "      <th>VisitorType_Returning_Visitor</th>\n",
       "      <th>Weekend_False</th>\n",
       "      <th>Weekend_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7460</td>\n",
       "      <td>0.508002</td>\n",
       "      <td>-0.200488</td>\n",
       "      <td>-0.3947</td>\n",
       "      <td>-0.244336</td>\n",
       "      <td>-0.399509</td>\n",
       "      <td>-0.483009</td>\n",
       "      <td>-0.454346</td>\n",
       "      <td>-0.668356</td>\n",
       "      <td>-0.320111</td>\n",
       "      <td>0.223142</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4687</td>\n",
       "      <td>-0.397089</td>\n",
       "      <td>-0.229562</td>\n",
       "      <td>-0.3947</td>\n",
       "      <td>-0.244336</td>\n",
       "      <td>-0.283724</td>\n",
       "      <td>-0.388159</td>\n",
       "      <td>-0.454346</td>\n",
       "      <td>-0.668356</td>\n",
       "      <td>-0.320111</td>\n",
       "      <td>-0.023995</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>-0.698787</td>\n",
       "      <td>-0.456792</td>\n",
       "      <td>-0.3947</td>\n",
       "      <td>-0.244336</td>\n",
       "      <td>-0.422666</td>\n",
       "      <td>-0.538272</td>\n",
       "      <td>-0.454346</td>\n",
       "      <td>-0.251598</td>\n",
       "      <td>-0.320111</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9057</td>\n",
       "      <td>1.111396</td>\n",
       "      <td>-0.102539</td>\n",
       "      <td>-0.3947</td>\n",
       "      <td>-0.244336</td>\n",
       "      <td>0.341513</td>\n",
       "      <td>-0.040404</td>\n",
       "      <td>-0.308034</td>\n",
       "      <td>-0.544755</td>\n",
       "      <td>-0.320111</td>\n",
       "      <td>0.964551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>-0.698787</td>\n",
       "      <td>-0.456792</td>\n",
       "      <td>-0.3947</td>\n",
       "      <td>-0.244336</td>\n",
       "      <td>-0.677393</td>\n",
       "      <td>-0.669486</td>\n",
       "      <td>-0.454346</td>\n",
       "      <td>1.173716</td>\n",
       "      <td>-0.320111</td>\n",
       "      <td>1.705961</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Administrative  Administrative_Duration  Informational  \\\n",
       "7460        0.508002                -0.200488        -0.3947   \n",
       "4687       -0.397089                -0.229562        -0.3947   \n",
       "790        -0.698787                -0.456792        -0.3947   \n",
       "9057        1.111396                -0.102539        -0.3947   \n",
       "225        -0.698787                -0.456792        -0.3947   \n",
       "\n",
       "      Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "7460               -0.244336       -0.399509                -0.483009   \n",
       "4687               -0.244336       -0.283724                -0.388159   \n",
       "790                -0.244336       -0.422666                -0.538272   \n",
       "9057               -0.244336        0.341513                -0.040404   \n",
       "225                -0.244336       -0.677393                -0.669486   \n",
       "\n",
       "      BounceRates  ExitRates  PageValues  TrafficType  ...  Region_5  \\\n",
       "7460    -0.454346  -0.668356   -0.320111     0.223142  ...         0   \n",
       "4687    -0.454346  -0.668356   -0.320111    -0.023995  ...         0   \n",
       "790     -0.454346  -0.251598   -0.320111    -0.271132  ...         0   \n",
       "9057    -0.308034  -0.544755   -0.320111     0.964551  ...         0   \n",
       "225     -0.454346   1.173716   -0.320111     1.705961  ...         0   \n",
       "\n",
       "      Region_6  Region_7  Region_8  Region_9  VisitorType_New_Visitor  \\\n",
       "7460         0         0         0         0                        1   \n",
       "4687         0         0         0         0                        0   \n",
       "790          0         0         0         0                        0   \n",
       "9057         0         0         0         0                        0   \n",
       "225          0         0         0         0                        0   \n",
       "\n",
       "      VisitorType_Other  VisitorType_Returning_Visitor  Weekend_False  \\\n",
       "7460                  0                              0              1   \n",
       "4687                  0                              1              1   \n",
       "790                   0                              1              1   \n",
       "9057                  0                              1              1   \n",
       "225                   0                              1              0   \n",
       "\n",
       "      Weekend_True  \n",
       "7460             0  \n",
       "4687             0  \n",
       "790              0  \n",
       "9057             0  \n",
       "225              1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "X_Train.drop(labels=['Browser_1','BounceRates','ProductRelated','VisitorType_Returning_Visitor'], \n",
    "                 axis=1, inplace=True)\n",
    "X_Test.drop(labels=['Browser_1','BounceRates','ProductRelated','VisitorType_Returning_Visitor'], \n",
    "                axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = X_Train.drop(['Weekend_True','Region_2','Region_1','Month_Jul','Month_Feb','Informational','Browser_9','Browser_12',\n",
    "                        'Browser_11','Region_8','Region_3','OperatingSystems_6','OperatingSystems_1','Month_June',\n",
    "                        'Browser_8','Browser_7','Browser_3','Browser_13','Browser_10','VisitorType_Other','Region_8','Region_7',\n",
    "                        'Region_5','OperatingSystems_5','Month_Aug'],axis=1)\n",
    "X_Test = X_Test.drop(['Weekend_True','Region_2','Region_1','Month_Jul','Month_Feb','Informational','Browser_9','Browser_12',\n",
    "                        'Browser_11','Region_8','Region_3','OperatingSystems_6','OperatingSystems_1','Month_June',\n",
    "                        'Browser_8','Browser_7','Browser_3','Browser_13','Browser_10','VisitorType_Other','Region_8','Region_7',\n",
    "                        'Region_5','OperatingSystems_5','Month_Aug'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8631, 23) (3699, 23)\n"
     ]
    }
   ],
   "source": [
    "X_Train = X_Train.drop(['OperatingSystems_4','OperatingSystems_7','OperatingSystems_8','Browser_5','Region_9'],axis=1)\n",
    "X_Test = X_Test.drop(['OperatingSystems_4','OperatingSystems_7','OperatingSystems_8','Browser_5','Region_9'],axis=1)\n",
    "\n",
    "print(X_Train.shape, X_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm=SMOTE(random_state=33,sampling_strategy=0.6)\n",
    "sm\n",
    "X_Train_res, y_Train_res = sm.fit_sample(X_Train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.625\n",
       "1    0.375\n",
       "Name: Revenue, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_Train_res,columns=['Revenue']).Revenue.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train : (11672, 23)\n",
      "Shape of y_train : (11672,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of x_train :\", X_Train_res.shape) \n",
    "print(\"Shape of y_train :\", y_Train_res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Training Accuracy : 0.8313913639479096\n",
      "Testing Accuracy : 0.8845633955123007\n",
      "ROC AUC Score : 0.786021142273141\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2904  223]\n",
      " [ 204  368]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      3127\n",
      "           1       0.62      0.64      0.63       572\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.78      0.79      0.78      3699\n",
      "weighted avg       0.89      0.88      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.8302775505280204\n",
      "Standard Deviation : 0.005752434663923313\n",
      "Mean precision score : 0.8538870761134303\n",
      "Standard Deviation precision score : 0.006761760988823408\n",
      "Mean recall score : 0.6604939239104313\n",
      "Standard Deviation recall score : 0.01803087811207932\n",
      "Mean f1 score : 0.7446835687707559\n",
      "Standard Deviation f1 score : 0.011411195415976865\n",
      "Mean AUC ROC Score : 0.796319081766554\n",
      "Standard Deviation AUC ROC Score : 0.00806033427111586\n",
      "*******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_lg = LogisticRegression() \n",
    "classifier_lg.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_lg)\n",
    "\n",
    "y_pred=classifier_lg.predict(X_Test)\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# evaluating the model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Training Accuracy :\", classifier_lg.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_lg.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_lg, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                          fit_intercept=True,\n",
      "                                          intercept_scaling=1, l1_ratio=None,\n",
      "                                          max_iter=100, multi_class='warn',\n",
      "                                          n_jobs=None, penalty='l2',\n",
      "                                          random_state=None, solver='warn',\n",
      "                                          tol=0.0001, verbose=0,\n",
      "                                          warm_start=False),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid=[{'C': [0.1, 0.01, 1],\n",
      "                          'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
      "                                     'saga']}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'C': 1, 'solver': 'liblinear'}\n",
      "Best Accuracy Score: 0.8302775873886223\n",
      "Best Estimators: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_classifier = LogisticRegression(penalty='l2')\n",
    "params = [\n",
    "    {\n",
    "     'C' : [0.1, 0.01,1],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "best_classifier = GridSearchCV(base_classifier, param_grid=params, n_jobs=-1,cv=10)\n",
    "\n",
    "#Learning\n",
    "best_classifier.fit(X_Train_res,y_Train_res)\n",
    "print(best_classifier)\n",
    "#The best hyper parameters set\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",best_classifier.best_params_)\n",
    "print(\"Best Accuracy Score:\",best_classifier.best_score_)\n",
    "print(\"Best Estimators:\",best_classifier.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Hyper parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Training Accuracy : 0.8313913639479096\n",
      "Testing Accuracy : 0.8845633955123007\n",
      "ROC AUC Score : 0.786021142273141\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2904  223]\n",
      " [ 204  368]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      3127\n",
      "           1       0.62      0.64      0.63       572\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.78      0.79      0.78      3699\n",
      "weighted avg       0.89      0.88      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.8302775505280204\n",
      "Standard Deviation : 0.005752434663923313\n",
      "Mean precision score : 0.8538870761134303\n",
      "Standard Deviation precision score : 0.006761760988823408\n",
      "Mean recall score : 0.6604939239104313\n",
      "Standard Deviation recall score : 0.01803087811207932\n",
      "Mean f1 score : 0.7446835687707559\n",
      "Standard Deviation f1 score : 0.011411195415976865\n",
      "Mean AUC ROC Score : 0.796319081766554\n",
      "Standard Deviation AUC ROC Score : 0.00806033427111586\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_lg = LogisticRegression(C=1,solver='liblinear') \n",
    "classifier_lg.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_lg)\n",
    "\n",
    "y_pred=classifier_lg.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Training Accuracy :\", classifier_lg.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_lg.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_lg, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Training Accuracy : 0.7485435229609322\n",
      "Testing Accuracy : 0.7280346039470127\n",
      "ROC AUC Score : 0.7484359660167142\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2248  879]\n",
      " [ 127  445]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.72      0.82      3127\n",
      "           1       0.34      0.78      0.47       572\n",
      "\n",
      "    accuracy                           0.73      3699\n",
      "   macro avg       0.64      0.75      0.64      3699\n",
      "weighted avg       0.85      0.73      0.76      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.7475148840956775\n",
      "Standard Deviation : 0.00918783014454218\n",
      "Mean precision score : 0.6301505763438531\n",
      "Standard Deviation precision score : 0.01170813257273663\n",
      "Mean recall score : 0.7918670261120342\n",
      "Standard Deviation recall score : 0.016346149248968406\n",
      "Mean f1 score : 0.701689113190776\n",
      "Standard Deviation f1 score : 0.009968105437216851\n",
      "Mean AUC ROC Score : 0.7563834632598994\n",
      "Standard Deviation AUC ROC Score : 0.00898603870125971\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_nb = GaussianNB() \n",
    "classifier_nb.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_nb)\n",
    "\n",
    "y_pred=classifier_nb.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_nb.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_nb.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_nb, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Training Accuracy : 0.924006168608636\n",
      "Testing Accuracy : 0.8104893214382265\n",
      "ROC AUC Score : 0.738638040884603\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2635  492]\n",
      " [ 209  363]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      3127\n",
      "           1       0.42      0.63      0.51       572\n",
      "\n",
      "    accuracy                           0.81      3699\n",
      "   macro avg       0.68      0.74      0.70      3699\n",
      "weighted avg       0.85      0.81      0.82      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.8803149182556247\n",
      "Standard Deviation : 0.013627777679221123\n",
      "Mean precision score : 0.7931128877289995\n",
      "Standard Deviation precision score : 0.015483091559512607\n",
      "Mean recall score : 0.9216534486902187\n",
      "Standard Deviation recall score : 0.036520093814899214\n",
      "Mean f1 score : 0.8521648125495164\n",
      "Standard Deviation f1 score : 0.018669227538946488\n",
      "Mean AUC ROC Score : 0.8885821408473549\n",
      "Standard Deviation AUC ROC Score : 0.017205666746363254\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier_knn = KNeighborsClassifier() \n",
    "classifier_knn.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_knn)\n",
    "\n",
    "y_pred=classifier_knn.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_knn.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_knn.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_knn, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                            metric='minkowski',\n",
      "                                            metric_params=None, n_jobs=None,\n",
      "                                            n_neighbors=5, p=2,\n",
      "                                            weights='uniform'),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid=[{'algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
      "                                        'brute'],\n",
      "                          'leaf_size': [30, 35, 40],\n",
      "                          'n_neighbors': [5, 8, 10, 15],\n",
      "                          'weights': ['uniform', 'distance']}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Best Accuracy Score: 0.896932830705963\n",
      "Best Estimators: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='distance')\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "base_classifier = KNeighborsClassifier()\n",
    "params = [\n",
    "    {\n",
    "     'n_neighbors':[5,8,10,15],\n",
    "        'leaf_size':[30,35,40],\n",
    "        'weights':['uniform', 'distance'],\n",
    "        'algorithm':['auto', 'ball_tree','kd_tree','brute']\n",
    "    }\n",
    "]\n",
    "\n",
    "best_classifier = GridSearchCV(base_classifier, param_grid=params, n_jobs=-1,cv=10)\n",
    "\n",
    "#Learning\n",
    "best_classifier.fit(X_Train_res,y_Train_res)\n",
    "print(best_classifier)\n",
    "#The best hyper parameters set\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",best_classifier.best_params_)\n",
    "print(\"Best Accuracy Score:\",best_classifier.best_score_)\n",
    "print(\"Best Estimators:\",best_classifier.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Hyper-parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='distance')\n",
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8123817247904839\n",
      "ROC AUC Score : 0.7361861834999027\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2647  480]\n",
      " [ 214  358]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.88      3127\n",
      "           1       0.43      0.63      0.51       572\n",
      "\n",
      "    accuracy                           0.81      3699\n",
      "   macro avg       0.68      0.74      0.70      3699\n",
      "weighted avg       0.85      0.81      0.83      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.8969334630579782\n",
      "Standard Deviation : 0.010807152677239959\n",
      "Mean precision score : 0.8045974585356858\n",
      "Standard Deviation precision score : 0.013762047008033098\n",
      "Mean recall score : 0.9582014147936846\n",
      "Standard Deviation recall score : 0.026381238463604063\n",
      "Mean f1 score : 0.8744799121940477\n",
      "Standard Deviation f1 score : 0.013869328306602948\n",
      "Mean AUC ROC Score : 0.909186864076099\n",
      "Standard Deviation AUC ROC Score : 0.012930375112783981\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classifier_knn = KNeighborsClassifier(algorithm='auto',leaf_size=30,n_neighbors=5,weights='distance') \n",
    "classifier_knn.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_knn)\n",
    "\n",
    "y_pred=classifier_knn.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_knn.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_knn.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_knn, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Training Accuracy : 0.8664324880054832\n",
      "Testing Accuracy : 0.8845633955123007\n",
      "ROC AUC Score : 0.8038768474889357\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2879  248]\n",
      " [ 179  393]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3127\n",
      "           1       0.61      0.69      0.65       572\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.78      0.80      0.79      3699\n",
      "weighted avg       0.89      0.88      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.8614672619761311\n",
      "Standard Deviation : 0.008319500978091435\n",
      "Mean precision score : 0.852879657675056\n",
      "Standard Deviation precision score : 0.011670334663992529\n",
      "Mean recall score : 0.7621767342716529\n",
      "Standard Deviation recall score : 0.02046745728479886\n",
      "Mean f1 score : 0.8048172954511124\n",
      "Standard Deviation f1 score : 0.013182109122609316\n",
      "Mean AUC ROC Score : 0.8416090654089347\n",
      "Standard Deviation AUC ROC Score : 0.010341020582847063\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC() \n",
    "classifier_svc.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_svc)\n",
    "\n",
    "y_pred=classifier_svc.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_svc.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_svc.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_svc, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                           decision_function_shape='ovr', degree=3,\n",
      "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
      "                           probability=False, random_state=None, shrinking=True,\n",
      "                           tol=0.001, verbose=False),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid=[{'C': [0.1, 1, 5, 7, 8, 9, 10, 100, 1000],\n",
      "                          'gamma': [1, 0.1, 0.01, 0.002, 0.0005, 0.001, 0.0001],\n",
      "                          'kernel': ['rbf']}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'C': 9, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Best Accuracy Score: 0.9425119945167924\n",
      "Best Estimators: SVC(C=9, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
      "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "base_classifier = SVC()\n",
    "params = [\n",
    "    {\n",
    "     'C': [0.1,1,5,7,8,9,10, 100, 1000],\n",
    "        'gamma': [1,0.1,0.01,0.002,0.0005,0.001,0.0001],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "]\n",
    "\n",
    "best_classifier = GridSearchCV(base_classifier, param_grid=params, n_jobs=-1,cv=10)\n",
    "\n",
    "#Learning\n",
    "best_classifier.fit(X_Train_res,y_Train_res)\n",
    "print(best_classifier)\n",
    "#The best hyper parameters set\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",best_classifier.best_params_)\n",
    "print(\"Best Accuracy Score:\",best_classifier.best_score_)\n",
    "print(\"Best Estimators:\",best_classifier.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine hyper-parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=9, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
      "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "Training Accuracy : 0.9924605894448252\n",
      "Testing Accuracy : 0.8502297918356313\n",
      "ROC AUC Score : 0.6357246047844065\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2959  168]\n",
      " [ 386  186]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      3127\n",
      "           1       0.53      0.33      0.40       572\n",
      "\n",
      "    accuracy                           0.85      3699\n",
      "   macro avg       0.71      0.64      0.66      3699\n",
      "weighted avg       0.83      0.85      0.84      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9425207569599483\n",
      "Standard Deviation : 0.01876988244652491\n",
      "Mean precision score : 0.9107670108449997\n",
      "Standard Deviation precision score : 0.01036549004745089\n",
      "Mean recall score : 0.9383384010950546\n",
      "Standard Deviation recall score : 0.045038989322164866\n",
      "Mean f1 score : 0.9239769396783266\n",
      "Standard Deviation f1 score : 0.026569818277759217\n",
      "Mean AUC ROC Score : 0.9416850319547845\n",
      "Standard Deviation AUC ROC Score : 0.02396918281347752\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(C=9,gamma=1,kernel='rbf') \n",
    "classifier_svc.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_svc)\n",
    "\n",
    "y_pred=classifier_svc.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_svc.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_svc.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_svc, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "Training Accuracy : 0.8935058259081563\n",
      "Testing Accuracy : 0.8756420654230873\n",
      "ROC AUC Score : 0.7886010296067859\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2860  267]\n",
      " [ 193  379]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      3127\n",
      "           1       0.59      0.66      0.62       572\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.76      0.79      0.77      3699\n",
      "weighted avg       0.88      0.88      0.88      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.8894083190988475\n",
      "Standard Deviation : 0.0325894925102643\n",
      "Mean precision score : 0.8594184484829144\n",
      "Standard Deviation precision score : 0.015148602985321979\n",
      "Mean recall score : 0.8414825031608204\n",
      "Standard Deviation recall score : 0.08725913463599862\n",
      "Mean f1 score : 0.8485729169545422\n",
      "Standard Deviation f1 score : 0.0527178594418722\n",
      "Mean AUC ROC Score : 0.8798227480946821\n",
      "Standard Deviation AUC ROC Score : 0.04346789279262193\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn. ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier_adb = AdaBoostClassifier() \n",
    "classifier_adb.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_adb)\n",
    "\n",
    "y_pred=classifier_adb.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_adb.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_adb.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_adb, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                                          base_estimator=None,\n",
      "                                          learning_rate=1.0, n_estimators=50,\n",
      "                                          random_state=None),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid=[{'base_estimator': [DecisionTreeClassifier(class_weight=None,\n",
      "                                                                    criterion='gini',\n",
      "                                                                    max_depth=1,\n",
      "                                                                    max_features=None,\n",
      "                                                                    max_leaf_nodes=None,\n",
      "                                                                    min_impurity_decrease=0.0,\n",
      "                                                                    min_impurity_split=None,\n",
      "                                                                    min_samples_leaf=1,\n",
      "                                                                    min_samples_split=2,\n",
      "                                                                    min_weight_fraction_leaf=0.0,\n",
      "                                                                    presort=False,\n",
      "                                                                    random_state=None,\n",
      "                                                                    splitter='best')],\n",
      "                          'learning_rate': [1, 0.1, 0.01, 0.001],\n",
      "                          'n_estimators': [50, 100, 200, 500]}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1, 'n_estimators': 500}\n",
      "Best Accuracy Score: 0.9029300891021247\n",
      "Best Estimators: AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=1,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=None,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1, n_estimators=500, random_state=None)\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "base_classifier = AdaBoostClassifier()\n",
    "params = [\n",
    "    {\n",
    "     'n_estimators': [50,100,200,500],\n",
    "          'learning_rate': [1,0.1,0.01,0.001],\n",
    "          'base_estimator':[DecisionTreeClassifier(max_depth=1)]\n",
    "    }\n",
    "]\n",
    "\n",
    "best_classifier = GridSearchCV(base_classifier, param_grid=params, n_jobs=-1,cv=10)\n",
    "\n",
    "#Learning\n",
    "best_classifier.fit(X_Train_res,y_Train_res)\n",
    "print(best_classifier)\n",
    "#The best hyper parameters set\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",best_classifier.best_params_)\n",
    "print(\"Best Accuracy Score:\",best_classifier.best_score_)\n",
    "print(\"Best Estimators:\",best_classifier.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Hyper-parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=1,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=None,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1, n_estimators=500, random_state=None)\n",
      "Training Accuracy : 0.917837559972584\n",
      "Testing Accuracy : 0.8832116788321168\n",
      "ROC AUC Score : 0.7730797743989303\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2916  211]\n",
      " [ 221  351]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      3127\n",
      "           1       0.62      0.61      0.62       572\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.78      0.77      0.78      3699\n",
      "weighted avg       0.88      0.88      0.88      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9029561990388141\n",
      "Standard Deviation : 0.05865217629343127\n",
      "Mean precision score : 0.8832212586025141\n",
      "Standard Deviation precision score : 0.016338195584060945\n",
      "Mean recall score : 0.8508834623783998\n",
      "Standard Deviation recall score : 0.16434564798606152\n",
      "Mean f1 score : 0.8592328722765032\n",
      "Standard Deviation f1 score : 0.09992698540254893\n",
      "Mean AUC ROC Score : 0.8925413422157515\n",
      "Standard Deviation AUC ROC Score : 0.07976426986456743\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classifier_adb = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=None, splitter='best'),learning_rate=1, n_estimators=500) \n",
    "classifier_adb.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_adb)\n",
    "\n",
    "y_pred=classifier_adb.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_adb.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_adb.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_adb, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Training Accuracy : 0.9169808087731323\n",
      "Testing Accuracy : 0.8886185455528521\n",
      "ROC AUC Score : 0.8084179970972424\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2891  236]\n",
      " [ 176  396]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3127\n",
      "           1       0.63      0.69      0.66       572\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.81      0.80      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9059443315427247\n",
      "Standard Deviation : 0.036131223849901924\n",
      "Mean precision score : 0.8766088618434782\n",
      "Standard Deviation precision score : 0.015639660904542343\n",
      "Mean recall score : 0.8705014471855638\n",
      "Standard Deviation recall score : 0.09695318832361988\n",
      "Mean f1 score : 0.8712940127427942\n",
      "Standard Deviation f1 score : 0.05719688470064401\n",
      "Mean AUC ROC Score : 0.8988554927454964\n",
      "Standard Deviation AUC ROC Score : 0.048214560546826914\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier_gb = GradientBoostingClassifier() \n",
    "classifier_gb.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_gb)\n",
    "\n",
    "y_pred=classifier_gb.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_gb.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_gb.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_gb, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
      "                                                  init=None, learning_rate=0.1,\n",
      "                                                  loss='deviance', max_depth=3,\n",
      "                                                  max_features=None,\n",
      "                                                  max_leaf_nodes=None,\n",
      "                                                  min_impurity_decrease=0.0,\n",
      "                                                  min_impurity_split=None,\n",
      "                                                  min_samples_leaf=1,\n",
      "                                                  min_samples_split=2,\n",
      "                                                  min_weight_fraction_leaf=0.0,\n",
      "                                                  n_estimators=100,\n",
      "                                                  n_iter_no_change=None,\n",
      "                                                  presort='auto',\n",
      "                                                  random_state=None,\n",
      "                                                  subsample=1.0, tol=0.0001,\n",
      "                                                  validation_fraction=0.1,\n",
      "                                                  verbose=0, warm_start=False),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid=[{'learning_rate': [1, 0.1, 0.01, 0.001],\n",
      "                          'max_depth': [1, 3, 5],\n",
      "                          'n_estimators': [100, 150, 200, 500]}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best Accuracy Score: 0.9184372858122002\n",
      "Best Estimators: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier()\n",
    "params = [\n",
    "    {\n",
    "    'n_estimators': [100,150,200,500],\n",
    "          'learning_rate': [1,0.1,0.01,0.001],\n",
    "        'max_depth': [1, 3, 5]\n",
    "    }\n",
    "]\n",
    "\n",
    "best_classifier = GridSearchCV(base_classifier, param_grid=params, n_jobs=-1,cv=10)\n",
    "\n",
    "#Learning\n",
    "best_classifier.fit(X_Train_res,y_Train_res)\n",
    "print(best_classifier)\n",
    "#The best hyper parameters set\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",best_classifier.best_params_)\n",
    "print(\"Best Accuracy Score:\",best_classifier.best_score_)\n",
    "print(\"Best Estimators:\",best_classifier.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Hyper-parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Training Accuracy : 0.9655586017820424\n",
      "Testing Accuracy : 0.8929440389294404\n",
      "ROC AUC Score : 0.7895495134861941\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2937  190]\n",
      " [ 206  366]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      3127\n",
      "           1       0.66      0.64      0.65       572\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.80      0.79      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9187181393961017\n",
      "Standard Deviation : 0.04892950578433094\n",
      "Mean precision score : 0.8953796095905906\n",
      "Standard Deviation precision score : 0.013140413675279284\n",
      "Mean recall score : 0.8853740217130079\n",
      "Standard Deviation recall score : 0.13757224180704158\n",
      "Mean f1 score : 0.8852063457846533\n",
      "Standard Deviation f1 score : 0.07903557914631189\n",
      "Mean AUC ROC Score : 0.9120487749544427\n",
      "Standard Deviation AUC ROC Score : 0.06660816103535108\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier_gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=200,max_depth=5) \n",
    "classifier_gb.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_gb)\n",
    "\n",
    "y_pred=classifier_gb.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_gb.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_gb.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_gb, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                        criterion='gini',\n",
      "                                                        max_depth=None,\n",
      "                                                        max_features=None,\n",
      "                                                        max_leaf_nodes=None,\n",
      "                                                        min_impurity_decrease=0.0,\n",
      "                                                        min_impurity_split=None,\n",
      "                                                        min_samples_leaf=1,\n",
      "                                                        min_samples_split=2,\n",
      "                                                        min_weight_fraction_leaf=0.0,\n",
      "                                                        presort=False,\n",
      "                                                        random_state=1,\n",
      "                                                        splitter='best'),\n",
      "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=10, n_jobs=None,\n",
      "                  oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "Training Accuracy : 0.9940027416038383\n",
      "Testing Accuracy : 0.8794268721276021\n",
      "ROC AUC Score : 0.7729838917079083\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2899  228]\n",
      " [ 218  354]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      3127\n",
      "           1       0.61      0.62      0.61       572\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.77      0.77      0.77      3699\n",
      "weighted avg       0.88      0.88      0.88      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.912454264560154\n",
      "Standard Deviation : 0.0331963905557503\n",
      "Mean precision score : 0.8840098802215055\n",
      "Standard Deviation precision score : 0.0091085476246499\n",
      "Mean recall score : 0.8819263763936345\n",
      "Standard Deviation recall score : 0.09714666623335988\n",
      "Mean f1 score : 0.8803186473851378\n",
      "Standard Deviation f1 score : 0.053080584368486235\n",
      "Mean AUC ROC Score : 0.9063485913574614\n",
      "Standard Deviation AUC ROC Score : 0.04592410823911377\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "classifier_bagt = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1)) \n",
    "classifier_bagt.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_bagt)\n",
    "\n",
    "y_pred=classifier_bagt.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_bagt.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_bagt.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_bagt, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Tree hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                                               criterion='gini',\n",
      "                                                                               max_depth=None,\n",
      "                                                                               max_features=None,\n",
      "                                                                               max_leaf_nodes=None,\n",
      "                                                                               min_impurity_decrease=0.0,\n",
      "                                                                               min_impurity_split=None,\n",
      "                                                                               min_samples_leaf=1,\n",
      "                                                                               min_samples_split=2,\n",
      "                                                                               min_weight_fraction_leaf=0.0,\n",
      "                                                                               presort=False,\n",
      "                                                                               random_state=...\n",
      "                                         bootstrap=True,\n",
      "                                         bootstrap_features=False,\n",
      "                                         max_features=1.0, max_samples=1.0,\n",
      "                                         n_estimators=10, n_jobs=None,\n",
      "                                         oob_score=False, random_state=None,\n",
      "                                         verbose=0, warm_start=False),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid=[{'max_features': [10, 15, 23],\n",
      "                          'max_samples': [10, 15, 20],\n",
      "                          'n_estimators': [10, 20, 50]}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'max_features': 23, 'max_samples': 20, 'n_estimators': 50}\n",
      "Best Accuracy Score: 0.8650616860863605\n",
      "Best Estimators: BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                        criterion='gini',\n",
      "                                                        max_depth=None,\n",
      "                                                        max_features=None,\n",
      "                                                        max_leaf_nodes=None,\n",
      "                                                        min_impurity_decrease=0.0,\n",
      "                                                        min_impurity_split=None,\n",
      "                                                        min_samples_leaf=1,\n",
      "                                                        min_samples_split=2,\n",
      "                                                        min_weight_fraction_leaf=0.0,\n",
      "                                                        presort=False,\n",
      "                                                        random_state=1,\n",
      "                                                        splitter='best'),\n",
      "                  bootstrap=True, bootstrap_features=False, max_features=23,\n",
      "                  max_samples=20, n_estimators=50, n_jobs=None, oob_score=False,\n",
      "                  random_state=None, verbose=0, warm_start=False)\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "base_classifier = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "params = [\n",
    "    {\n",
    "    'n_estimators': [10,20,50],\n",
    "        'max_features': [10,15,23],\n",
    "        'max_samples':[10,15,20]\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "best_classifier = GridSearchCV(base_classifier, param_grid=params, n_jobs=-1,cv=10)\n",
    "\n",
    "#Learning\n",
    "best_classifier.fit(X_Train_res,y_Train_res)\n",
    "print(best_classifier)\n",
    "#The best hyper parameters set\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",best_classifier.best_params_)\n",
    "print(\"Best Accuracy Score:\",best_classifier.best_score_)\n",
    "print(\"Best Estimators:\",best_classifier.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Tree hyper-parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                        criterion='gini',\n",
      "                                                        max_depth=None,\n",
      "                                                        max_features=None,\n",
      "                                                        max_leaf_nodes=None,\n",
      "                                                        min_impurity_decrease=0.0,\n",
      "                                                        min_impurity_split=None,\n",
      "                                                        min_samples_leaf=1,\n",
      "                                                        min_samples_split=2,\n",
      "                                                        min_weight_fraction_leaf=0.0,\n",
      "                                                        presort=False,\n",
      "                                                        random_state=1,\n",
      "                                                        splitter='best'),\n",
      "                  bootstrap=True, bootstrap_features=False, max_features=23,\n",
      "                  max_samples=20, n_estimators=50, n_jobs=None, oob_score=False,\n",
      "                  random_state=None, verbose=0, warm_start=False)\n",
      "Training Accuracy : 0.8689170664838931\n",
      "Testing Accuracy : 0.8718572587185726\n",
      "ROC AUC Score : 0.819931188095563\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2799  328]\n",
      " [ 146  426]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      3127\n",
      "           1       0.56      0.74      0.64       572\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.76      0.82      0.78      3699\n",
      "weighted avg       0.89      0.87      0.88      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.8644667001722472\n",
      "Standard Deviation : 0.010703080182529141\n",
      "Mean precision score : 0.8353415447968036\n",
      "Standard Deviation precision score : 0.0158045289060029\n",
      "Mean recall score : 0.7957660679393541\n",
      "Standard Deviation recall score : 0.026230717874465456\n",
      "Mean f1 score : 0.8147827385179081\n",
      "Standard Deviation f1 score : 0.01609185400834282\n",
      "Mean AUC ROC Score : 0.8507271439345379\n",
      "Standard Deviation AUC ROC Score : 0.013021227784452001\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classifier_bagt = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1),\n",
    "                                    max_features=23, max_samples=20, n_estimators=50) \n",
    "classifier_bagt.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_bagt)\n",
    "\n",
    "y_pred=classifier_bagt.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_bagt.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_bagt.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_bagt, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8496891051635577\n",
      "ROC AUC Score : 0.7375394432877644\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2814  313]\n",
      " [ 243  329]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      3127\n",
      "           1       0.51      0.58      0.54       572\n",
      "\n",
      "    accuracy                           0.85      3699\n",
      "   macro avg       0.72      0.74      0.73      3699\n",
      "weighted avg       0.86      0.85      0.85      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.8806721404780818\n",
      "Standard Deviation : 0.038104133937551604\n",
      "Mean precision score : 0.8327270714691697\n",
      "Standard Deviation precision score : 0.01610994464473537\n",
      "Mean recall score : 0.8510861728472461\n",
      "Standard Deviation recall score : 0.1086272185790569\n",
      "Mean f1 score : 0.8389380436555512\n",
      "Standard Deviation f1 score : 0.06268628008307917\n",
      "Mean AUC ROC Score : 0.8747544286638845\n",
      "Standard Deviation AUC ROC Score : 0.052116351573739\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classifier_dt = DecisionTreeClassifier()\n",
    "classifier_dt.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_dt)\n",
    "\n",
    "y_pred=classifier_dt.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_dt.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_dt.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_dt, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features=None,\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              presort=False, random_state=None,\n",
      "                                              splitter='best'),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
      "                          'max_depth': [1, 2, 3, 4, 5, 6],\n",
      "                          'max_features': ['auto', 'sqrt', 'log2'],\n",
      "                          'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
      "                                               11],\n",
      "                          'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
      "                                                12, 13, 14, 15],\n",
      "                          'random_state': [123]}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 13, 'random_state': 123}\n",
      "Best Accuracy Score: 0.7579677861549006\n",
      "Best Estimators: DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=13,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=123, splitter='best')\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "base_classifier = DecisionTreeClassifier()\n",
    "params = [\n",
    "    {\n",
    "    'criterion':['gini','entropy'],\n",
    "          'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],\n",
    "          'random_state':[123],\n",
    "          'max_depth':[1,2,3,4,5,6]\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "best_classifier = GridSearchCV(base_classifier, param_grid=params, n_jobs=-1,cv=10)\n",
    "\n",
    "#Learning\n",
    "best_classifier.fit(X_Train_res,y_Train_res)\n",
    "print(best_classifier)\n",
    "#The best hyper parameters set\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",best_classifier.best_params_)\n",
    "print(\"Best Accuracy Score:\",best_classifier.best_score_)\n",
    "print(\"Best Estimators:\",best_classifier.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Hyper-parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=13,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=123, splitter='best')\n",
      "Training Accuracy : 0.7754455106237149\n",
      "Testing Accuracy : 0.8148148148148148\n",
      "ROC AUC Score : 0.6733447237124883\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2746  381]\n",
      " [ 304  268]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      3127\n",
      "           1       0.41      0.47      0.44       572\n",
      "\n",
      "    accuracy                           0.81      3699\n",
      "   macro avg       0.66      0.67      0.66      3699\n",
      "weighted avg       0.82      0.81      0.82      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.757968821719203\n",
      "Standard Deviation : 0.029463312779062268\n",
      "Mean precision score : 0.7199228155147429\n",
      "Standard Deviation precision score : 0.04498331686617979\n",
      "Mean recall score : 0.5814608737448147\n",
      "Standard Deviation recall score : 0.06271564133028114\n",
      "Mean f1 score : 0.6417973617355763\n",
      "Standard Deviation f1 score : 0.05088296351163041\n",
      "Mean AUC ROC Score : 0.7226667542146101\n",
      "Standard Deviation AUC ROC Score : 0.03456494251742551\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classifier_dt = DecisionTreeClassifier(criterion='entropy', max_depth=6,\n",
    "                                       max_features='auto', min_samples_leaf=1, min_samples_split=13, random_state=123)\n",
    "classifier_dt.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_dt)\n",
    "\n",
    "y_pred=classifier_dt.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_dt.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_dt.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_dt, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8861854555285212\n",
      "ROC AUC Score : 0.7905516693092645\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2905  222]\n",
      " [ 199  373]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      3127\n",
      "           1       0.63      0.65      0.64       572\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.79      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9253915229843835\n",
      "Standard Deviation : 0.033269765672810175\n",
      "Mean precision score : 0.8893545545489612\n",
      "Standard Deviation precision score : 0.009705539944107349\n",
      "Mean recall score : 0.9141359205040593\n",
      "Standard Deviation recall score : 0.09308300040983199\n",
      "Mean f1 score : 0.8994316882776768\n",
      "Standard Deviation f1 score : 0.05072660019866658\n",
      "Mean AUC ROC Score : 0.923139986108429\n",
      "Standard Deviation AUC ROC Score : 0.045180400603128806\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier(n_estimators=200)\n",
    "classifier_rf.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_rf)\n",
    "\n",
    "y_pred=classifier_rf.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_rf.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_rf.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_rf, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "\n",
      "{'n_estimators': [50, 112, 175, 237, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 12, 15, 17, 20, None], 'min_samples_split': [2, 5, 10, 15], 'min_samples_leaf': [1, 2, 4, 10], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'n_estimators': 112, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
      "Best Accuracy Score: 0.9203221384509939\n",
      "Best Estimators: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=112,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "## Hyper Parameter Tuning\n",
    "print('Parameters currently in use:\\n')\n",
    "print(classifier_rf.get_params())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 300, num = 5)] ## play with start and stop\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 20,num = 5)] ## change 10,20 and 2\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,15]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,10]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = classifier_rf, param_distributions = random_grid, n_iter = 100, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_Train_res, y_Train_res)\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",rf_random.best_params_)\n",
    "print(\"Best Accuracy Score:\",rf_random.best_score_)\n",
    "print(\"Best Estimators:\",rf_random.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Hyper-parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=112,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Training Accuracy : 1.0\n",
      "Testing Accuracy : 0.8883482022168153\n",
      "ROC AUC Score : 0.7939735352591125\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2910  217]\n",
      " [ 196  376]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      3127\n",
      "           1       0.63      0.66      0.65       572\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.79      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9261630251721925\n",
      "Standard Deviation : 0.03337584270858893\n",
      "Mean precision score : 0.8922921622663177\n",
      "Standard Deviation precision score : 0.010877547534411232\n",
      "Mean recall score : 0.9127650125910367\n",
      "Standard Deviation recall score : 0.09386072327151383\n",
      "Mean f1 score : 0.9001730809665173\n",
      "Standard Deviation f1 score : 0.05101072200397596\n",
      "Mean AUC ROC Score : 0.9234828689615837\n",
      "Standard Deviation AUC ROC Score : 0.04539327560021292\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classifier_rf = RandomForestClassifier(n_estimators=112,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=\n",
    "                                       None,bootstrap=True)\n",
    "classifier_rf.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_rf)\n",
    "\n",
    "y_pred=classifier_rf.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_rf.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_rf.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_rf, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Training Accuracy : 0.9119259766963673\n",
      "Testing Accuracy : 0.8856447688564477\n",
      "ROC AUC Score : 0.8109444920285982\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2874  253]\n",
      " [ 170  402]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      3127\n",
      "           1       0.61      0.70      0.66       572\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.78      0.81      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9059415421794709\n",
      "Standard Deviation : 0.02997755649413667\n",
      "Mean precision score : 0.8753664715308969\n",
      "Standard Deviation precision score : 0.012319413101262673\n",
      "Mean recall score : 0.872779850161437\n",
      "Standard Deviation recall score : 0.0827600242232721\n",
      "Mean f1 score : 0.8723530007588852\n",
      "Standard Deviation f1 score : 0.04728565552369985\n",
      "Mean AUC ROC Score : 0.8993090110870698\n",
      "Standard Deviation AUC ROC Score : 0.040446105000121996\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier_xgb = XGBClassifier()\n",
    "classifier_xgb.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_xgb)\n",
    "\n",
    "y_pred=classifier_xgb.predict(X_Test.values)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_xgb.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_xgb.score(X_Test.values, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_xgb, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                                     colsample_bylevel=1, colsample_bynode=1,\n",
      "                                     colsample_bytree=1, gamma=0,\n",
      "                                     learning_rate=0.1, max_delta_step=0,\n",
      "                                     max_depth=3, min_child_weight=1,\n",
      "                                     missing=None, n_estimators=100, n_jobs=1,\n",
      "                                     nthread=None, objective='binary:logistic',\n",
      "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "                                     scale_pos_weight=1, seed=None, silent=None,\n",
      "                                     subsample=1, verbosity=1),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid=[{'learning_rate': [1, 0.1, 0.01, 0.015, 0.025, 0.05],\n",
      "                          'n_estimators': [100, 150, 200], 'n_jobs': [-1]}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "*******************************************************************************************\n",
      "Best Hyper Parameters: {'learning_rate': 0.1, 'n_estimators': 200, 'n_jobs': -1}\n",
      "Best Accuracy Score: 0.9138108293351611\n",
      "Best Estimators: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "base_classifier = XGBClassifier()\n",
    "params = [\n",
    "    {\n",
    "   'n_estimators': [100,150,200],\n",
    "          'learning_rate': [1,0.1,0.01,0.015,0.025,0.05],\n",
    "        'n_jobs':[-1]\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "best_classifier = GridSearchCV(base_classifier, param_grid=params, n_jobs=-1,cv=10)\n",
    "\n",
    "#Learning\n",
    "best_classifier.fit(X_Train_res,y_Train_res)\n",
    "print(best_classifier)\n",
    "#The best hyper parameters set\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"Best Hyper Parameters:\",best_classifier.best_params_)\n",
    "print(\"Best Accuracy Score:\",best_classifier.best_score_)\n",
    "print(\"Best Estimators:\",best_classifier.best_estimator_)\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST Hyper-parameter tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=-1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Training Accuracy : 0.9305174777244688\n",
      "Testing Accuracy : 0.8905109489051095\n",
      "ROC AUC Score : 0.7938242601658015\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2920  207]\n",
      " [ 198  374]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      3127\n",
      "           1       0.64      0.65      0.65       572\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.79      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9138306607946429\n",
      "Standard Deviation : 0.04524375476427685\n",
      "Mean precision score : 0.8898398429041035\n",
      "Standard Deviation precision score : 0.01243788284636845\n",
      "Mean recall score : 0.8773690479922258\n",
      "Standard Deviation recall score : 0.12602102205508206\n",
      "Mean f1 score : 0.8793838700247296\n",
      "Standard Deviation f1 score : 0.07310289703649062\n",
      "Mean AUC ROC Score : 0.906538029454895\n",
      "Standard Deviation AUC ROC Score : 0.061364843212023096\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classifier_xgb = XGBClassifier(learning_rate=0.1, n_estimators=200, n_jobs=-1)\n",
    "classifier_xgb.fit(X_Train_res,y_Train_res)\n",
    "print(classifier_xgb)\n",
    "\n",
    "y_pred=classifier_xgb.predict(X_Test.values)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", classifier_xgb.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", classifier_xgb.score(X_Test.values, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = classifier_xgb, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method VotingClassifier.fit of VotingClassifier(estimators=[('dt',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='entropy',\n",
      "                                                     max_depth=6,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=13,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=123,\n",
      "                                                     splitter='best')),\n",
      "                             ('svm',\n",
      "                              SVC(C=9, cache_size=200, clas...\n",
      "                                                     random_state=None,\n",
      "                                                     verbose=0,\n",
      "                                                     warm_start=False)),\n",
      "                             ('lr',\n",
      "                              LogisticRegression(C=1, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='liblinear', tol=0.0001,\n",
      "                                                 verbose=0,\n",
      "                                                 warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)>\n",
      "Training Accuracy : 0.9671007539410555\n",
      "Testing Accuracy : 0.8837523655041903\n",
      "ROC AUC Score : 0.7519727234709646\n",
      "*******************************************************************************************\n",
      "CONFUSION MATRIX\n",
      "[[2948  179]\n",
      " [ 251  321]]\n",
      "*******************************************************************************************\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3127\n",
      "           1       0.64      0.56      0.60       572\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.78      0.75      0.77      3699\n",
      "weighted avg       0.88      0.88      0.88      3699\n",
      "\n",
      "*******************************************************************************************\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 0.9056791854890169\n",
      "Standard Deviation : 0.021205751982915716\n",
      "Mean precision score : 0.8975295963151275\n",
      "Standard Deviation precision score : 0.007456945433588685\n",
      "Mean recall score : 0.844887830057574\n",
      "Standard Deviation recall score : 0.06173144117184842\n",
      "Mean f1 score : 0.8692581606209906\n",
      "Standard Deviation f1 score : 0.03441058668395356\n",
      "Mean AUC ROC Score : 0.8935186655784235\n",
      "Standard Deviation AUC ROC Score : 0.029246970319591753\n",
      "*******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lr_vc = LogisticRegression(C=1,solver='liblinear')\n",
    "svm_vc=SVC(C=9,gamma=1,kernel='rbf')\n",
    "knn_vc=KNeighborsClassifier(algorithm='auto',leaf_size=30,n_neighbors=5,weights='distance')\n",
    "nb_vc=GaussianNB()\n",
    "dt_vc=DecisionTreeClassifier(criterion='entropy', max_depth=6,\n",
    "                                       max_features='auto', min_samples_leaf=1, min_samples_split=13, random_state=123)\n",
    "rf_vc=RandomForestClassifier(n_estimators=112,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=\n",
    "                                       None,bootstrap=True)\n",
    "\n",
    "evc = VotingClassifier(estimators= [('dt',dt_vc),('svm',svm_vc),('knn',knn_vc),('nb',nb_vc),('rf',rf_vc),('lr',lr_vc)], \n",
    "                       voting = 'hard')\n",
    "evc.fit(X_Train_res,y_Train_res)\n",
    "print(evc.fit)\n",
    "\n",
    "\n",
    "y_pred=evc.predict(X_Test)\n",
    "\n",
    "# evaluating the model\n",
    "print(\"Training Accuracy :\", evc.score(X_Train_res, y_Train_res))\n",
    "print(\"Testing Accuracy :\", evc.score(X_Test, y_Test))\n",
    "print(\"ROC AUC Score :\", roc_auc_score(y_Test, y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_Test,y_pred))\n",
    "print(\"*******************************************************************************************\")\n",
    "\n",
    "# cross validation\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = evc, X = X_Train_res, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2910  217]\n",
      " [ 196  376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      3127\n",
      "           1       0.63      0.66      0.65       572\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.79      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 1.0\n",
      "Standard Deviation : 0.0\n",
      "Mean precision score : 1.0\n",
      "Standard Deviation precision score : 0.0\n",
      "Mean recall score : 1.0\n",
      "Standard Deviation recall score : 0.0\n",
      "Mean f1 score : 1.0\n",
      "Standard Deviation f1 score : 0.0\n",
      "Mean AUC ROC Score : 1.0\n",
      "Standard Deviation AUC ROC Score : 0.0\n",
      "*******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Algorithm 1: xgboost\n",
    "pred_val_xgb=classifier_xgb.predict(X_Train_res)\n",
    "test_pred_xgb=classifier_xgb.predict(X_Test.values)\n",
    "\n",
    "## Algorithm 2: Random Forest\n",
    "pred_val_rf=classifier_rf.predict(X_Train_res)\n",
    "test_pred_rf=classifier_rf.predict(X_Test)\n",
    "\n",
    "## Algorithm 3: Decision Tree\n",
    "pred_val_dt=classifier_dt.predict(X_Train_res)\n",
    "test_pred_dt=classifier_dt.predict(X_Test)\n",
    "\n",
    "stacked_predictions=np.column_stack((pred_val_rf,pred_val_xgb,pred_val_dt)) ## Prediction by the algorithms on training data\n",
    "#stacked_predictions[0:10]\n",
    "stacked_test_predictions=np.column_stack((test_pred_rf,test_pred_xgb,test_pred_dt)) ## Prediction by the algorithms on testing data\n",
    "#stacked_test_predictions[0:10]\n",
    "\n",
    "## Building Meta Model\n",
    "lr_stack = LogisticRegression()\n",
    "lr_stack.fit(stacked_predictions,y_Train_res) ## stacked_predictions=X_train\n",
    "\n",
    "y_pred_stack=lr_stack.predict(stacked_test_predictions) ## stacked_test_predictions=X_test\n",
    "y_pred_stack\n",
    "\n",
    "\n",
    "# evaluating the model\n",
    "cm = confusion_matrix(y_Test, y_pred_stack)\n",
    "print(cm)\n",
    "print(classification_report(y_Test, y_pred_stack)) \n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = lr_stack, X = stacked_predictions, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2910  217]\n",
      " [ 196  376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      3127\n",
      "           1       0.63      0.66      0.65       572\n",
      "\n",
      "    accuracy                           0.89      3699\n",
      "   macro avg       0.79      0.79      0.79      3699\n",
      "weighted avg       0.89      0.89      0.89      3699\n",
      "\n",
      "CROSS VALIDATION METRICS\n",
      "Mean Accuracy : 1.0\n",
      "Standard Deviation : 0.0\n",
      "Mean precision score : 1.0\n",
      "Standard Deviation precision score : 0.0\n",
      "Mean recall score : 1.0\n",
      "Standard Deviation recall score : 0.0\n",
      "Mean f1 score : 1.0\n",
      "Standard Deviation f1 score : 0.0\n",
      "Mean AUC ROC Score : 1.0\n",
      "Standard Deviation AUC ROC Score : 0.0\n",
      "*******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\neera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Algorithm 1: xgboost\n",
    "pred_val_xgb=classifier_xgb.predict(X_Train_res)\n",
    "test_pred_xgb=classifier_xgb.predict(X_Test.values)\n",
    "\n",
    "## Algorithm 2: Random Forest\n",
    "pred_val_rf=classifier_rf.predict(X_Train_res)\n",
    "test_pred_rf=classifier_rf.predict(X_Test)\n",
    "\n",
    "## Algorithm 3: Decision Tree\n",
    "pred_val_dt=classifier_dt.predict(X_Train_res)\n",
    "test_pred_dt=classifier_dt.predict(X_Test)\n",
    "\n",
    "stacked_predictions=np.column_stack((pred_val_rf,pred_val_xgb,pred_val_dt)) ## Prediction by the algorithms on training data\n",
    "#stacked_predictions[0:10]\n",
    "stacked_test_predictions=np.column_stack((test_pred_rf,test_pred_xgb,test_pred_dt)) ## Prediction by the algorithms on testing data\n",
    "#stacked_test_predictions[0:10]\n",
    "\n",
    "stacked_predictions=pd.DataFrame(stacked_predictions)\n",
    "stacked_test_predictions=pd.DataFrame(stacked_test_predictions)\n",
    "\n",
    "\n",
    "## Building Meta Model\n",
    "lr_stack = LogisticRegression()\n",
    "lr_stack.fit(stacked_predictions,y_Train_res) ## stacked_predictions=X_train\n",
    "\n",
    "y_pred_stack=lr_stack.predict(stacked_test_predictions) ## stacked_test_predictions=X_test\n",
    "y_pred_stack\n",
    "\n",
    "\n",
    "# evaluating the model\n",
    "cm = confusion_matrix(y_Test, y_pred_stack)\n",
    "print(cm)\n",
    "print(classification_report(y_Test, y_pred_stack)) \n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'AUC ROC score' : make_scorer(roc_auc_score)}\n",
    "cvs = cross_validate(estimator = lr_stack, X = stacked_predictions, y = y_Train_res, cv = 10,scoring=scoring)\n",
    "#print(cvs)\n",
    "print(\"CROSS VALIDATION METRICS\")\n",
    "print(\"Mean Accuracy :\", np.mean(cvs['test_accuracy']))\n",
    "print(\"Standard Deviation :\", np.std(cvs['test_accuracy']))\n",
    "print(\"Mean precision score :\", np.mean(cvs['test_precision']))\n",
    "print(\"Standard Deviation precision score :\", np.std(cvs['test_precision']))\n",
    "print(\"Mean recall score :\", np.mean(cvs['test_recall']))\n",
    "print(\"Standard Deviation recall score :\", np.std(cvs['test_recall']))\n",
    "print(\"Mean f1 score :\", np.mean(cvs['test_f1_score']))\n",
    "print(\"Standard Deviation f1 score :\", np.std(cvs['test_f1_score']))\n",
    "print(\"Mean AUC ROC Score :\", np.mean(cvs['test_AUC ROC score']))\n",
    "print(\"Standard Deviation AUC ROC Score :\", np.std(cvs['test_AUC ROC score']))\n",
    "print(\"*******************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
